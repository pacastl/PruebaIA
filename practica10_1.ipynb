{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "practica10_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pacastl/PruebaIA/blob/main/practica10_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgIZGKPCLpt1"
      },
      "source": [
        "# Práctica 10.1: Redes recurrentes\n",
        "\n",
        "En este notebook vamos a presentar en detalle cómo trabajar con distintas versiones de redes recurrentes. Para ello vamos a usar la librería fastai, que ya usamos en el entregable 2, y su librería subyacente que es PyTorch. Este notebook está basado en el libro de [fastai](https://github.com/fastai/fastbook).\n",
        "\n",
        "Para profundizar en los conceptos de redes recurrentes vamos a construir un modelo de lenguaje desde cero. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq2sNX3FMU4C"
      },
      "source": [
        "## Instalación librería\n",
        "\n",
        "Para utilizar este notebook es necesario instalar la versión más actual de la librería de fastai. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFxBd1yXMf0X",
        "outputId": "41fac6f7-7271-4ca1-93c8-0486d49fbdf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install fastai --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.10/dist-packages (2.7.12)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai) (23.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.5.29)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.15.2+cu118)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai) (2.27.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai) (6.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai) (8.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastai) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai) (1.10.1)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai) (3.5.2)\n",
            "Requirement already satisfied: torch<2.1,>=1.7 in /usr/local/lib/python3.10/dist-packages (from fastai) (2.0.1+cu118)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.22.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.7->fastai) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.7->fastai) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.7->fastai) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.7->fastai) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=1.7->fastai) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=1.7->fastai) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=1.7->fastai) (16.0.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4->fastai) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4->fastai) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=1.7->fastai) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vkVIIsQLkXu"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZnyse_yLkXw"
      },
      "source": [
        "Para este notebook vamos a utilizar un dataset llamado *human numbers* que consta de los 10000 primeros números escritos en inglés. Para descargar dicho dataset ejecutamos la siguiente instrucción y creamos una variable path que apunta a donde se ha descargado dicho dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Na6OmG4LkX0"
      },
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QHSKt6CNcxB"
      },
      "source": [
        "Como podemos ver a través de la siguiente instrucción, nuestro dataset consta de dos ficheros de texto plano, uno para entrenar y otro para validar (o testear)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEvMzkcfLkYB",
        "outputId": "d3a5bbb3-9699-4f33-c7f0-007b298c8c6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/human_numbers/train.txt'),Path('/root/.fastai/data/human_numbers/valid.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9YwuQE1LkYI"
      },
      "source": [
        "Vamos a combinar ambos dataset y almacenamos el resultado en una variable lines. En el código siguiente aparece un objeto `L()` que es un tipo de lista utilizado en FastAI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2aAKcQSLkYJ",
        "outputId": "0b3a1e7f-2783-40c9-9e81-87347a5f4e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lines = L()\n",
        "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: lines += L(*f.readlines())\n",
        "lines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erdAQ5mrLkYO"
      },
      "source": [
        "A continuación vamos a formar una única cadena con la lista anterior y a separar cada número mediante un '.'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGLu9gjDLkYP",
        "outputId": "c25f6a4c-b3e8-4d60-a3a3-0107dd7b499b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text = ' . '.join([l.strip() for l in lines])\n",
        "text[:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_xpDO__LkYU"
      },
      "source": [
        "Seguidamente aplicamos un proceso de tokenización separando por espacios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R6eOa7eLkYW",
        "outputId": "890ff5dd-b430-4055-ef70-96e9c28005eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens = text.split(' ')\n",
        "tokens[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKAEvMAOLkYb"
      },
      "source": [
        "Como comentamos en teoría, inicialmente la representación de cada palabra suele darse mediante el método one-hot encoding, y se utiliza la red para aprender un embedding de los datos. Sin embargo, la representación one-hot ocupa mucha memoria por lo que en FastAI en lugar de usar dicha representación, se **numericalizan** las palabras. Este proceso consite en representar cada palabra mediante el índice (la posición) que ocupa en el vocabulario. \n",
        "\n",
        "Por lo tanto lo primero que tenemos que hacer es construir nuestro vocabulario con las palabras únicas de nuestro dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2c-EYwiLkYc",
        "outputId": "b7bd8171-271e-4457-e4c1-06519c9b00ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab = L(*tokens).unique()\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bymHidMaLkYh"
      },
      "source": [
        "Ahora podemos convertir los tokens en números mirando su índice en el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "520vBLMSLkYi",
        "outputId": "5bf2cbc0-b2fa-4e13-9968-de9514410924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "nums = L(word2idx[i] for i in tokens)\n",
        "nums"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2D6PyI3LkYn"
      },
      "source": [
        "Ahora que ya tenemos codificados nuestros datos ya podemos empezar a construir modelos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg1aPnAfLkYo"
      },
      "source": [
        "## Un primer modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqeJ-u2RLkYp"
      },
      "source": [
        "Nuestro objetivo para este dataset va a ser predecir una palabra basándonos en las tres anteriores. Por lo tanto podemos ver un la lista de cada secuencia de tres palabras consecutivas como nuestra \"X\", y la siguiente palabra de la secuencia como nuestra \"y\". \n",
        "\n",
        "Esto lo podemos lograr en python del siguiente modo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRIIiIFCLkYq",
        "outputId": "0afeb66b-6d5d-4562-def8-7495d59c17f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "L((tokens[i:i+3], tokens[i+3]) for i in range(0,len(tokens)-4,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TCE_I9oLkY1"
      },
      "source": [
        "Ahora creamos una serie de *tensores* (puede verse como otro tipo de lista) con los valores numéricos, que es lo que el modelo espera como entrada. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24mEsSQQLkY2",
        "outputId": "7ee6c333-7352-4c8f-d4fc-9bd1f32704b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0,len(nums)-4,3))\n",
        "seqs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_LzaG_mLkY6"
      },
      "source": [
        "Ahora podemos preparar una serie de *batches* que serán usados para entrenar la red. Para ello es necesario usar la clase `DataLoader` y separar en un conjunto de entrenamiento y de test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg66KcvXLkY8"
      },
      "source": [
        "# Tamaño del batch\n",
        "bs = 64\n",
        "# Partición qu vamos a hacer\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSAZMRdZLkZA"
      },
      "source": [
        "Ahora vamos a crear una red neuronal que tome tres palabras como entradas y devuelva una predicción para cada palabra del vocabulario indicando la probabilidad de que esa palabra sea la siguiente en la secuencia. En esta red neuronal vamos a tener tres capas completamente conectadas, pero con dos pequeños cambios. \n",
        "\n",
        "El primer cambio es que la primera capa solo usará el embedding de la primera palabra como entrada, la segunda capa usará el embedding de la segunda palabra mas la salida de la primera capa como entrada, y la tercera capa usará el embedding de la tercera palabra más la salida de la segunda capa como entrada. El efecto clave de este proceso es que cada palabra se interpreta en el contexto de las palabras precedentes. \n",
        "\n",
        "El segundo cambio es que cada una de las capas va usar la misma matriz de pesos. Esto se hace con el objetivo de que el impacto que tiene una palabra en los pesos a partir de las palabras previas no debería cambiar dependiendo de la posición de la palabra. Dicho de otro modo, los los valores de entrada de las capas van cambiando a medida que los datos van pasando a través de las capas, pero los pesos no deben cambiar. De este modo una capa no aprende una posición en la secuencia, sino que tiene que aprender todas ellas. \n",
        "\n",
        "Dado que los pesos de la capa no cambian, se puede ver las capas secuenciales como la misma capa repetida. Esto en la práctica se puede llevar a cabo con PyTorch creando una capa y usándola múltiples veces. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRa8CxcpLkZB"
      },
      "source": [
        "### Nuestro modelo de lenguaje en Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGbeDzFLkZC"
      },
      "source": [
        "Vamos a crear el modelo de lenguaje descrito anteriormente en PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38UZcScBLkZC"
      },
      "source": [
        "class LMModel1(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.h_h(self.i_h(x[:,0])))\n",
        "        h = h + self.i_h(x[:,1])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        h = h + self.i_h(x[:,2])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9twGXVaLkZG"
      },
      "source": [
        "Cuando queremos crear una red neuronal en PyTorch debemos crear una clase que herede de la clase `Module`. Además debemos proporcionar como se va a calcular la salida a partir de la entrada (es decir la arquitectura de la red) dentro del método `forward`. Además, como vemos en la clase anterior, es normal inicializar una serie de parámetros, en este caso las capas que se van a utilizar, dentro del constructor (método `__init__`) de la clase. \n",
        "\n",
        "En este caso tenemos tres capas:\n",
        "\n",
        "- La capa de embedding (`i_h` por de *input* a *hidden*).\n",
        "- La capa lineal que crea la salida para la siguiente palabra(`h_h` por de *hidden* a *hidden*).\n",
        "- Una capa final para predecir la siguiente palabra (`h_o` por de *hidden* a *output*)\n",
        "\n",
        "Esto puede verse mejor con la siguiente representación gráfica. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJmjGq3qLkZJ"
      },
      "source": [
        "<img alt=\"Pictorial representation of simple neural network\" width=\"400\" src=\"https://github.com/IA1920/images/blob/master/images/att_00020.png?raw=1\" caption=\"Pictorial representation of simple neural network\" id=\"img_simple_nn\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDs3ASWlLkZK"
      },
      "source": [
        "Cada forma representa una capa: el rectángulo para la entrada, el círculo para la capa oculta, y el triángulo para la capa de salida. Usaremos la misma representación para el resto de diagramas del notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFlItrioLkZL"
      },
      "source": [
        "<img alt=\"Shapes used in our pictorial representations\" width=\"200\" src=\"https://github.com/IA1920/images/blob/master/images/att_00021.png?raw=1\" id=\"img_shapes\" caption=\"Shapes used in our pictorial representations\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or17DjVcLkZM"
      },
      "source": [
        "Una flecha en el diagrama representa el cálculo realizado, es decir el producto de los pesos por la entrada de la capa seguido de la aplicación de una función de activación. Usando esta notación podemos representar nuestro modelo del siguiente modo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkBI2czwLkZN"
      },
      "source": [
        "<img alt=\"Representation of our basic language model\" width=\"500\" caption=\"Representation of our basic language model\" id=\"lm_rep\" src=\"https://github.com/IA1920/images/blob/master/images/att_00022.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gIz560ELkZO"
      },
      "source": [
        "Notar que hemos coloreado las flechas de maenra que todas las flechas del mismo color usan la misma matriz de pesos. Por ejemplo, todas las capas de entrada usan la misma matriz de embedding. \n",
        "\n",
        "Vamos a entrenar dicho modelo. Para ello debemos constrir un objeto `Learner` que va a recibir 4 parámetros. \n",
        "- Un dataloader (`dls`) que indica cómo acceder al dataset.\n",
        "- La arquitectura de nuestro modelo (`LMModel1`).\n",
        "- La función de pérdida (`loss_func=F.cross_entropy` que es la función de pérdida utilizada normalmente para clasificación cuando hay múltiples clases). \n",
        "- La métrica con la que evaluaremos el modelo (`metrics=accuracy`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_gwiutMqvA"
      },
      "source": [
        "learn = Learner(dls, LMModel1(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74rQLtTUMqvB"
      },
      "source": [
        "Ahora ya podemos entrenar nuestro modelo con el método `fit_one_cycle` que vimos en el Entregable 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d42ilrwbLkZP",
        "outputId": "27ac4a2d-36e8-4b71-d6b5-fd9cf970a800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.745608</td>\n",
              "      <td>1.822046</td>\n",
              "      <td>0.467079</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.409058</td>\n",
              "      <td>1.680260</td>\n",
              "      <td>0.467079</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.406700</td>\n",
              "      <td>1.673412</td>\n",
              "      <td>0.493701</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.367404</td>\n",
              "      <td>1.639396</td>\n",
              "      <td>0.465177</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx6_fgurLkZS"
      },
      "source": [
        "Para ver qué tal funciona el modelo podemos compararlo con predecir siempre la palabra más común. Para ello vamos a encontrar con el siguiente código cuál es la palabra más común en el conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsYLX82pLkZT",
        "outputId": "7ef6e340-965e-4457-abd9-4afc7ed82ef9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n,counts = 0,torch.zeros(len(vocab))\n",
        "for x,y in dls.valid:\n",
        "    n += y.shape[0]\n",
        "    for i in range_of(vocab): counts[i] += (y==i).long().sum()\n",
        "idx = torch.argmax(counts)\n",
        "idx, vocab[idx.item()], counts[idx].item()/n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(29), 'thousand', 0.15165200855716662)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT0voN-3LkZZ"
      },
      "source": [
        "La palabra más común es \"thousand\", y usando esta palabra como predicción tendríamos una tasa de acierto del 15%, así que nuestro modelo que obtiene aproximadamente una tasa de acierto del 50% es considerablemente mejor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uYKrtCjLkZa"
      },
      "source": [
        "###  Nuestra primera red recurrente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnX-7wUHLkZb"
      },
      "source": [
        "Si nos fijamos en el código de nuestra red podemos notar que hay código que se repite, y que lo podríamos reemplazar usando un bucle. Esto tiene la ventaja de que podremos aplicar nuestra red a secuencias de tokens de distintas longitudes, evitando así estar restringidos a trabajar con secuencias de longitud 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI3bNEdtLkZb"
      },
      "source": [
        "class LMModel2(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = 0\n",
        "        for i in range(3):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMbPdo_bLkZg"
      },
      "source": [
        "Vamos a comprobar que se obtiene los mismos resultados (o muy similares)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugy6tQE4LkZh",
        "outputId": "7c7e95b4-3506-407b-f742-e35e36a07204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.882373</td>\n",
              "      <td>1.991688</td>\n",
              "      <td>0.449727</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.395768</td>\n",
              "      <td>1.794917</td>\n",
              "      <td>0.467316</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.402596</td>\n",
              "      <td>1.659027</td>\n",
              "      <td>0.489422</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.370055</td>\n",
              "      <td>1.698290</td>\n",
              "      <td>0.382458</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vwihnnvLkZk"
      },
      "source": [
        "También podemos refactorizar nuestra representación del mismo modo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnZcmleeLkZl"
      },
      "source": [
        "<img alt=\"Basic recurrent neural network\" width=\"400\" caption=\"Basic recurrent neural network\" id=\"basic_rnn\" src=\"https://github.com/IA1920/images/blob/master/images/att_00070.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtR8upOdLkZq"
      },
      "source": [
        "Ahora que tenemos una red RNN, vamos a mejorarla. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbv0VYe_LkZr"
      },
      "source": [
        "## Mejorando la RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbcC_B8KLkZr"
      },
      "source": [
        "Vamos a ver cómo mejorar la RNN que hemos construido. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdkWv_E8LkZs"
      },
      "source": [
        "### Manteniendo el estado de una RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9FKkGCCLkZu"
      },
      "source": [
        "Si nos fijamos en el código de nuestro modelo, el estado oculto (representando mediante `h`) se reinicia a 0 para cada nueva secuencia. Por lo tanto se pierde toda la información de las secuencias que habían aparecido anteriormente, lo que significa que el modelo no sabe en que punto de la secuencia global se encuentra. Esto se puede resolver facilmente moviendo la inicialización del estado oculto al constructor. \n",
        "\n",
        "Sin embargo, esto tiene un problema asociado, debido a que de este modo estaríamos construyendo una red neuronal tan profunda como el número de tokens de nuestro documento. Por ejemplo, si hay 10000 tokens en nuestro dataset, entonces crearíamos una red con 10000 capas. \n",
        "\n",
        "Para ver esto, consideremos la imagen original de nuestra red recurrente antes de refactorizarla incluyendo el bucle. En dicha imagen podemos ver que cada capa se corresponde con un token de entrada. \n",
        "\n",
        "<img alt=\"Pictorial representation of simple neural network\" width=\"400\" src=\"https://github.com/IA1920/images/blob/master/images/att_00020.png?raw=1\" caption=\"Pictorial representation of simple neural network\" id=\"img_simple_nn\">\n",
        "\n",
        "El problema con una red de 10000 capas es que cuando llegas a la palabra número diezmil del dataset, todavía necesitas calcular todas las derivadas que van hasta la primera capa. Esto es muy lento, y es bastante improbable que se pueda almacenar un batch en la GPU. \n",
        "\n",
        "La solución a este problema consiste en decir a PyTorch que no propague hacia atrás todas las derivadas en la red, y en su lugar se almacenan solo las tres últimas capas de gradientes. Esto se hace mediante el método `detach`.\n",
        "\n",
        "A continuación tenemos la nueva versión de nuestro modelo RNN. Ahora este modelo almacena el estado ya que recuerda las salidas entre las diferentes llamadas al método `forward`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGtbFxKILkZv"
      },
      "source": [
        "class LMModel3(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = 0\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for i in range(3):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "        out = self.h_o(self.h)\n",
        "        self.h = self.h.detach()\n",
        "        return out\n",
        "    \n",
        "    def reset(self): self.h = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbpjrrPLkZ0"
      },
      "source": [
        "Para usar `LMModel3`, nos tenemos que asegurar que el modelo va a ver las secuencias en un cierto orden. Es decir, el modelo tiene que ver las secuencias en el mismo orden que aparecen en el texto. Para ello tenemos que reorganizar el dataset.\n",
        "\n",
        "En primer lugar dividimos la muestra en `m = len(dset) // bs` grupos (esto es equivalente a partir el dataset completo en grupos de, por ejemplo, 64 piezas iguales (dado que estamos usando `bs=64`). Por lo tanto, `m` es la longitud de cada una de esas piezas. Por ejemplo, si usamos el dataset completo esto sería:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnypYX1XLkZ0",
        "outputId": "3c21bdf5-a89e-4bd2-fe3c-50e2d841547b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "m = len(seqs)//bs\n",
        "m,bs,len(seqs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(328, 64, 21031)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8MhoJG2LkZ5"
      },
      "source": [
        "El primer batch estaría compuesto por las muestras:\n",
        "\n",
        "    (0, m, 2*m, ..., (bs-1)*m)\n",
        "\n",
        "el segundo por las muestras: \n",
        "\n",
        "    (1, m+1, 2*m+1, ..., (bs-1)*m+1)\n",
        "\n",
        "y así sucesivamente. De este modo, en cada época, el modelo veo una parte continua del texto de tamaño  `3*m` (ya que cada secuencia de texto tiene tamaño 3)\n",
        "\n",
        "La siguiente función se encarga de ello. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ifUDoMyLkZ5"
      },
      "source": [
        "def group_chunks(ds, bs):\n",
        "    m = len(ds) // bs\n",
        "    new_ds = L()\n",
        "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
        "    return new_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OdpddSVLkZ8"
      },
      "source": [
        "Seguidamente definimos de nuevo nuestro `DataLoader` pero en este caso le indicamos que descarte el último batch que no tiene la dimensión adecuada (`drop_last=True`) ya que es raro que el tamaño sea divisible exactamente por el `bs`. También le indicamos que el texto se lea en orden mediante `shuffle=False`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHVM-CmhLkZ9"
      },
      "source": [
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(\n",
        "    group_chunks(seqs[:cut], bs), \n",
        "    group_chunks(seqs[cut:], bs), \n",
        "    bs=bs, drop_last=True, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2-BUFk1LkZ_"
      },
      "source": [
        "Ahora ya podemos definir nuestro nuevo `Learner` igual que antes con una salvedad. En concreto a nuestro bucle de entrenamiento le vamos a añadir un `Callback`, que son funciones que añaden funcionalidad al proceso de entrenamiento. En este caso el `Callback` va a llamar al método `reset` del modelo al principio de cada época y antes de la fase de validación. Esto hace que podamos empezar con un estado limpio antes de leer nuevos bloques de texto. Además ahora es posible entrenar el modelo por más tiempo sin sufrir overfitting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAjk6xVTLkaA",
        "outputId": "ec245d6c-9099-4135-e8c2-835dca05064d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "learn = Learner(dls, LMModel3(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.669218</td>\n",
              "      <td>1.794305</td>\n",
              "      <td>0.482212</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.309748</td>\n",
              "      <td>1.763255</td>\n",
              "      <td>0.439183</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.103899</td>\n",
              "      <td>1.789470</td>\n",
              "      <td>0.495433</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.019819</td>\n",
              "      <td>1.777843</td>\n",
              "      <td>0.493990</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.972519</td>\n",
              "      <td>1.859213</td>\n",
              "      <td>0.508654</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.923400</td>\n",
              "      <td>1.848902</td>\n",
              "      <td>0.554567</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.877592</td>\n",
              "      <td>1.809287</td>\n",
              "      <td>0.550481</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.821283</td>\n",
              "      <td>1.804795</td>\n",
              "      <td>0.588221</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.794130</td>\n",
              "      <td>1.900244</td>\n",
              "      <td>0.581010</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.772560</td>\n",
              "      <td>1.904992</td>\n",
              "      <td>0.584375</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428WyaklLkaF"
      },
      "source": [
        "### Creando más señal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhQbCZuiLkaF"
      },
      "source": [
        "Otro problema con la aproximación que estamos utilizando es que solo predecimos una palabra para cada tres palabras de entrada. Esto significa que la cantidad de información que le estamos pasando a los pesos cuando se actulizan no es todo lo grande que podría ser. Sería mejor si predijeramos la siguiente palabra a partir de la palabra anterior, en lugar de cada tres palabras como se muestra en la siguiente figura. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umJDJwr-LkaF"
      },
      "source": [
        "<img alt=\"RNN predicting after every token\" width=\"400\" caption=\"RNN predicting after every token\" id=\"stateful_rep\" src=\"https://github.com/IA1920/images/blob/master/images/att_00024.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbkK0geULkaH"
      },
      "source": [
        "Esto es bastante sencillo de añadir. Primero tenemos que cambiar nuestros datos de manera que nuestra \"y\" no sea la palabra que sigue a la última de las tres palabras de la secuencia sino que sea las tres palabras siguientes a cada una de la palabra de la sencuencia. En lugar de 3, vamos a usar un atributo, `ls` (por longitud de secuencia) y a hacerlas un poco más grandes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aczawZW5LkaH"
      },
      "source": [
        "ls = 16\n",
        "seqs = L((tensor(nums[i:i+ls]), tensor(nums[i+1:i+ls+1]))\n",
        "         for i in range(0,len(nums)-ls-1,ls))\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n",
        "                             group_chunks(seqs[cut:], bs),\n",
        "                             bs=bs, drop_last=True, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUWSAU23LkaL"
      },
      "source": [
        "Si nos fijamos en el primer elemento de `seqs`, vemos que contiene dos listas del mismo tamaño. La segunda es la misma lista que la primera pero desplazada una posición a la derecha. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT6-QN6iLkaM",
        "outputId": "af82b3a2-42cb-4e00-acac-6ff71bce4cb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "[L(vocab[o] for o in s) for s in seqs[0]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n",
              " (#16) ['.','two','.','three','.','four','.','five','.','six'...]]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wtuc6U6LkaQ"
      },
      "source": [
        "Ahora debemos modificar el modelo de manera que realice una predicción cada nueva palabra, en lugar de solo al final de la secuencia. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMYhPwPSLkaQ"
      },
      "source": [
        "class LMModel4(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = 0\n",
        "        \n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        for i in range(ls):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "            outs.append(self.h_o(self.h))\n",
        "        self.h = self.h.detach()\n",
        "        return torch.stack(outs, dim=1)\n",
        "    \n",
        "    def reset(self): self.h = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCSrhAhKLkaT"
      },
      "source": [
        "Este modelo va a devolver salidas de la forma `bs x sl x vocab_sz` (ya que las estamos apilando en `dim=1`). Nuestros objetivos son de la forma `bs x sl`, por lo tanto será necesario aplanarlas antes de calcular la pérdida. Es por esto por lo que definimos una nueva función de pérdida a partir de la `F.cross_entropy`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k6Eg1vWLkaT"
      },
      "source": [
        "def loss_func(inp, targ):\n",
        "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GXof288LkaV"
      },
      "source": [
        "Ahora podemos entrenar el modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG1H-k_aLkaX",
        "outputId": "6d45de41-d144-4916-fc7b-5d5ef765e37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.207180</td>\n",
              "      <td>3.041949</td>\n",
              "      <td>0.277588</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.292474</td>\n",
              "      <td>1.890991</td>\n",
              "      <td>0.471273</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.728666</td>\n",
              "      <td>1.816225</td>\n",
              "      <td>0.464355</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.458166</td>\n",
              "      <td>1.756371</td>\n",
              "      <td>0.499674</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.302754</td>\n",
              "      <td>1.756406</td>\n",
              "      <td>0.485189</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.190479</td>\n",
              "      <td>1.711861</td>\n",
              "      <td>0.528564</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.099712</td>\n",
              "      <td>1.720817</td>\n",
              "      <td>0.504720</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.005352</td>\n",
              "      <td>1.765341</td>\n",
              "      <td>0.584229</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.926608</td>\n",
              "      <td>1.737421</td>\n",
              "      <td>0.578451</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.846389</td>\n",
              "      <td>1.690032</td>\n",
              "      <td>0.593424</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.796557</td>\n",
              "      <td>1.683611</td>\n",
              "      <td>0.599365</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.770435</td>\n",
              "      <td>1.669299</td>\n",
              "      <td>0.614583</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.725265</td>\n",
              "      <td>1.687430</td>\n",
              "      <td>0.619222</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.696250</td>\n",
              "      <td>1.688340</td>\n",
              "      <td>0.629313</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.680154</td>\n",
              "      <td>1.709765</td>\n",
              "      <td>0.634928</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eIgRdPpLkaZ"
      },
      "source": [
        "Es necesario entrenar por más tiempo ya que la tarea es más compleja, y como vemos obtenemos mejores resultados.\n",
        "\n",
        "Para mejorar el modelo tenemos que aumentar la profundidad del modelo. En este momento nuestra red solo tiene una capa oculta, así que vamos a ver si es posible obtener mejores resultados añadiendo más capas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79X7k6-fLkaa"
      },
      "source": [
        "## RNNs multicapa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-D6clToLkaa"
      },
      "source": [
        "En una red RNN multicapa, las salidas de nuestra red recurrente se pasan como entrada a una nueva red RNN como se muestra en el siguiente diagrama."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic7xDpdcLkab"
      },
      "source": [
        "<img alt=\"2-layer RNN\" width=\"550\" caption=\"2-layer RNN\" id=\"stacked_rnn_rep\" src=\"https://github.com/IA1920/images/blob/master/images/att_00025.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrpXYxptLkac"
      },
      "source": [
        "O si usamos una representación expandida del siguiente modo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNyH4JXzLkac"
      },
      "source": [
        "<img alt=\"2-layer unrolled RNN\" width=\"500\" caption=\"2-layer unrolled RNN\" id=\"unrolled_stack_rep\" src=\"https://github.com/IA1920/images/blob/master/images/att_00026.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PMvn2QzLkac"
      },
      "source": [
        "Vamos a ver cómo implementar esto en la práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSGm_DcaLkad"
      },
      "source": [
        "## El modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nHCBWmPLkae"
      },
      "source": [
        "En lugar de implementar desde cero la red RNN vamos a utilizar la definición de RNN proporcionada por PyTorch que está implementada del mismo modo que hemos explicado anteriormente, pero que además nos da la opción de apilar capas RNN. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX0Fyf_qLkaf"
      },
      "source": [
        "class LMModel5(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = torch.zeros(n_layers, bs, n_hidden)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(res)\n",
        "    \n",
        "    def reset(self): self.h.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1QI5dL6MqvL"
      },
      "source": [
        "Ahora ya podemos entrenar nuestro nuevo modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co7wCUHmLkah",
        "outputId": "70082caa-02ce-4933-e557-de6052673897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "learn = Learner(dls, LMModel5(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.041719</td>\n",
              "      <td>2.675021</td>\n",
              "      <td>0.341227</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.161552</td>\n",
              "      <td>1.832430</td>\n",
              "      <td>0.468669</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.703228</td>\n",
              "      <td>2.001665</td>\n",
              "      <td>0.305745</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.463254</td>\n",
              "      <td>1.807079</td>\n",
              "      <td>0.504557</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.245308</td>\n",
              "      <td>2.066224</td>\n",
              "      <td>0.541585</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.073142</td>\n",
              "      <td>2.103547</td>\n",
              "      <td>0.547038</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.939051</td>\n",
              "      <td>2.172490</td>\n",
              "      <td>0.548177</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.833248</td>\n",
              "      <td>2.242725</td>\n",
              "      <td>0.563151</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.743320</td>\n",
              "      <td>2.332178</td>\n",
              "      <td>0.575765</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.669653</td>\n",
              "      <td>2.446482</td>\n",
              "      <td>0.574219</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.613939</td>\n",
              "      <td>2.512596</td>\n",
              "      <td>0.569906</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.575380</td>\n",
              "      <td>2.571442</td>\n",
              "      <td>0.573079</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.547775</td>\n",
              "      <td>2.637540</td>\n",
              "      <td>0.562988</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.530957</td>\n",
              "      <td>2.647874</td>\n",
              "      <td>0.565592</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.522227</td>\n",
              "      <td>2.666501</td>\n",
              "      <td>0.562907</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT94CggELkas"
      },
      "source": [
        "Como vemos los resultados son peores que con el modelo de una sola capa RNN ¿estamos haciendo algo mal? El problema cuando se aumenta la profundidad de las redes neuronales es que las salidas de las capas tienden o a explotar o a desaparecer, complicando de este modo el proceso de aprendizaje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLpJoJqpLkas"
      },
      "source": [
        "### Explosión y desaparición de salidas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNP8FturLkat"
      },
      "source": [
        "En la práctica, crear modelos usando RNN es difícil. Obtendremos mejores resultados si llamamos a la función  `detach` de manera frecuentemente y añadir más capas. De este modo la RNN tiene más tiempo para aprender descriptores más ricos. Pero esto también significa que tenemos un modelo más profundo que entrenar. El problema clave en el desarrollo del deep learning ha sido averiguar como entrenar este tipo de modelos. \n",
        "\n",
        "La razón para que esto sea complejo es lo que ocurre cuando multiplicamos una matriz varias veces. Para entender esto pensemos que ocurre cuando multiplicamos un número múltiples veces. Por ejemplo, si multiplicamos por 2 y empezamos por uno tenemos la secuencia 1, 2, 4, 8, ... y después de 32 pasos hemos llegado al número 4294967296. Algo parecido ocurre cuando multiplicamos por 0,5: obtenemos 0.5, 0.25, 0.125, ...  y después de 32 pasos tenemos 0.00000000023. Como podemos ver, un número ligeramente superior o inferior a 1 provoca una explosión o la desaparición de ese número después de unas pocas multiplicaciones.\n",
        "\n",
        "Debido a que la multiplicación de matrices es solo multiplicar números y sumarlos, el mismo problema aparece al multiplicar matrices. Y una red neuronal al final es una multiplicación repetidad de múltiples matrices. Esto significa que una red neuronal acabe trabajando con números extremadamente grandes o extremadamente pequeños. \n",
        "\n",
        "Esto es un problema debido al modo en el que los ordenadores almacenan los números (en \"coma flotante\"), ya que esta representación se vuelve menos precisa a medida que nos alejamos de cero. Esto se explica de forma clara en el artículo [What you never wanted to know about floating point but will be forced to find out](http://www.volkerschatz.com/science/float.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjKOfu8aLkau"
      },
      "source": [
        "Esto significa que los gradientes que se calculan al actualizar los pesos tienden siendo cero o infinito para las redes profundas. Este problema se conoce como *vanishing gradients* o *exploding gradients*. Esto significa eque en el proceso de propagación hacia atrás, los pesos o bien no se actualizan o saltan al infinito. En cualquiera de los dos casos esto impide el entrenamiento. \n",
        "\n",
        "Para resolver este problema, se han diseñado distintas aproximaciones. Una de ellas consiste en cambiar la definición de una capa de forma que se eviten los problemas. Para las RNNs existen dos tipos de capas que evitan estos problemas y son las GRUs, y las LSTM. Ambas están disponibles en PyTorch, pero nosotros nos centraremos en el uso de las LSTM, ya que las GRUs son una pequeña variante de las LSTM. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v85uppelLkau"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM9N9BSmLka_"
      },
      "source": [
        "Vamos a crear un modelo equivalente al `LMModel5`, usando una LSTM con dos capas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tuaefzzLka_"
      },
      "source": [
        "class LMModel6(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = [torch.zeros(2, bs, n_hidden) for _ in range(n_layers)]\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(res)\n",
        "    \n",
        "    def reset(self): \n",
        "        for h in self.h: h.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY4QkjT8MqvN"
      },
      "source": [
        "Pasamos a entrenar el modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ACpEPwvLkbC",
        "outputId": "88eac112-79e8-4cb0-b070-0bbff7564485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "learn = Learner(dls, LMModel6(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.980613</td>\n",
              "      <td>2.642134</td>\n",
              "      <td>0.417562</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.114207</td>\n",
              "      <td>2.058711</td>\n",
              "      <td>0.310547</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.580321</td>\n",
              "      <td>2.077430</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.300266</td>\n",
              "      <td>2.098867</td>\n",
              "      <td>0.476644</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.114432</td>\n",
              "      <td>2.211655</td>\n",
              "      <td>0.509603</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.951183</td>\n",
              "      <td>2.273859</td>\n",
              "      <td>0.549805</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.763615</td>\n",
              "      <td>2.188053</td>\n",
              "      <td>0.589600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.563757</td>\n",
              "      <td>2.046655</td>\n",
              "      <td>0.618327</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.347246</td>\n",
              "      <td>1.888653</td>\n",
              "      <td>0.654460</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.199093</td>\n",
              "      <td>1.822529</td>\n",
              "      <td>0.665202</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.116122</td>\n",
              "      <td>1.754515</td>\n",
              "      <td>0.698161</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.072431</td>\n",
              "      <td>1.810620</td>\n",
              "      <td>0.691976</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.050335</td>\n",
              "      <td>1.797071</td>\n",
              "      <td>0.700521</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.039335</td>\n",
              "      <td>1.794814</td>\n",
              "      <td>0.701172</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.034317</td>\n",
              "      <td>1.794649</td>\n",
              "      <td>0.699544</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8A4W_wnLkbF"
      },
      "source": [
        "En el modelo anterior se puede observar que se produce cierto sobreajuste que se puede resolver aplicando téncicas de regularización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQmDKbaJLkbF"
      },
      "source": [
        "## Reduciendo el sobreajuste en un LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXM7zusULkbH"
      },
      "source": [
        "Las redes recurrentes son díficiles de entrenar debido a los problemas comentado anteriormente. El uso de las LSTM permite entrenar las con más facilidad, pero estas redes tienden a sufrir de sobreajuste. Una técnica para reducir este problema consiste en utilizar *data augmentation* (que no solo se puede aplicar a imágenes sino también a texto). Sin embargo no se suele usar de manera tan habitual en procesado de lenguaje ya que esta técnica suele requerir un modelo que genere aumentos aleatorios (por ejemplo, traduciendo de un lenguaje a otro y volviendo al lenguaje original). \n",
        "\n",
        "Sin embargo existen otras técnicas para reducir el sobreajuste en un LSTM que fueron estudiadas de manera detallada en el artículo [Regularizing and Optimizing LSTM Language Models](https://arxiv.org/abs/1708.02182). Este artículo mostró que se pueden mejorar los resultados de las LSTMs aplicando tres técnicas *dropout*, *activation regularization*, y *temporal activation regularization*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9XScNegLkbH"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOZR6hWELkbI"
      },
      "source": [
        "Dropout es una técnica introducida por Geoffrey Hinton et al. en [Improving neural networks by preventing co-adaptation of feature detectors](https://arxiv.org/abs/1207.0580). La idea básica de esta técnica consiste en poner a cero algunas neuronas a medida que se van entrenando. Esto hace que todas las neuronas de la red trabajen para obtener una salida y así evitar neuronas sobre especializadas. Este método se representa con la siguiente figura:\n",
        "\n",
        "<img src=\"https://github.com/IA1920/images/blob/master/images/Dropout1.png?raw=1\" alt=\"A figure from the article showing how neurons go off with dropout\" width=\"800\" id=\"img_dropout\" caption=\"A screenshot from the dropout paper\">\n",
        "\n",
        "El autor del artículo explicaba esta técnica con la siguiente metáfora en una entrevista. \n",
        "\n",
        "> Fui al banco y me di cuenta que las personas que atendían en el banco cambiaban de manera frecuente. Al preguntar a uno de ellos por la razón de esto me dijo que no lo sabía pero que les movían de puesto de manera frecuente. Descubrí que esto debe deberse a que para defraudar al banco por parte de los empleados es necesario que cooperen. Esto me hizo darme cuenta de que eliminando de forma aleatoria un conjunto diferente de neuronas en cada batch del entrenamiento serviría para prevenir conspiraciones y reducir de este modo el sobreajuste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjk0cJXxLkbN"
      },
      "source": [
        "El uso del dropout no se aplica a todas las capas de la red, sino que es suficiente con aplicarlo justo antes de la última capa de nuestra LSTM para redcuir el sobreajuste. El dropout no solo se utilizan en LSTMs sino que también se puede aplicar en las redes convolucionales o en redes neuronales feed-forward. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS18C_T7LkbP"
      },
      "source": [
        "Por último hay que tener en cuenta que el dropout tiene un comportamiento diferente cuando estamos entrenando y cuando estamos usando el modelo ya entrenado. En concreto solo se desactivan neuronas durante el proceso de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVoKnGMRLkbP"
      },
      "source": [
        "### Las regularizaciones AR y TAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHfl3AsjLkbQ"
      },
      "source": [
        "AR (del inglés *activation regularization*) y TAR (del inglés *temporal activation regularization*) son dos métodos que reducen el sobreajuste incluyendo una penalización a la función de perdida. En concreto, la regularización AR se encarga de que sean las salidas producidas por LSTM lo más pequeñas posibles, mientras que la regularización TAR se encarga de que la salida de dos secuencias consecutivas de nuestro texto sean lo más pequeña posible. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oJh5WO6LkbQ"
      },
      "source": [
        "### Entrenando un modelo con Dropout, AR y TAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5l82wHELkbR"
      },
      "source": [
        "Podemos combinar el Dropout con las regularizaciones AR y TAR para entrenar nuestro modelo. Para ello tenemos que añadir una capa de dropout antes de la salida de nuestro LSTM. Además nuestro modelo debe devolver tres cosas: la salida normal de la red, la salida producida por la capa del dropout, y la salida antes de aplicar el dropout. Las dos últimas serán utilizadas por un callback llamado `RNNRegularization` que se usa para aplicar las regularizaciones AR y TAR.\n",
        "\n",
        "Otro truco que se suele utilizar en estas redes se conoce como *weight tying*. En un modelo de lenguaje, el embedding representa una función de palabras en inglés (o en otro idioma) a la entrada del modelo, y la salida representa una función de las salidas de la red a palabras en inglés. Podemos esperar que estas funciones sean la misma, esto se puede llevar a cabo asignando la misma matriz de pesos a ambas capas:\n",
        "\n",
        "    self.h_o.weight = self.i_h.weight\n",
        "\n",
        "Incluimos estos cambios en el nuevo modelo `LMMModel7`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vItch1FaLkbS"
      },
      "source": [
        "class LMModel7(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "        \n",
        "    def forward(self, x):\n",
        "        raw,h = self.rnn(self.i_h(x), self.h)\n",
        "        out = self.drop(raw)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(out),raw,out\n",
        "    \n",
        "    def reset(self): \n",
        "        for h in self.h: h.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDx7p9WILkbU"
      },
      "source": [
        "Seguidamente creamos nuestro `Learner` usando el callback de `RNNRegularizer` donde `alpha` es un parámetro para la regularización AR, y `beta` se aplica para la regularización TAR. Un `TextLearner` automáticamente añade dichos callbacks por nosotros, así que podemos construir el `Learner` con la siguiente línea:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvOLPonFLkbU"
      },
      "source": [
        "learn = TextLearner(dls, LMModel7(len(vocab), 64, 2, 0.4),\n",
        "                    loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV89N8_ILkbb"
      },
      "source": [
        "Ahora podemos entrenar el modelo añadiendo otra técnica de regularización llamada *weight decay* que añade una penalización a la pérdida para que los pesos sean lo más pequeños posibles. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRFllos_Lkbc",
        "outputId": "ee82b8a0-6bae-43b7-932b-14015dd2d5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.576557</td>\n",
              "      <td>2.051495</td>\n",
              "      <td>0.477620</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.612523</td>\n",
              "      <td>1.436273</td>\n",
              "      <td>0.644531</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.872200</td>\n",
              "      <td>1.040051</td>\n",
              "      <td>0.759766</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.426089</td>\n",
              "      <td>1.039442</td>\n",
              "      <td>0.783203</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.214413</td>\n",
              "      <td>0.899676</td>\n",
              "      <td>0.819010</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.116686</td>\n",
              "      <td>0.809990</td>\n",
              "      <td>0.848796</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.071381</td>\n",
              "      <td>0.755693</td>\n",
              "      <td>0.856608</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.049520</td>\n",
              "      <td>0.833040</td>\n",
              "      <td>0.863607</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.036043</td>\n",
              "      <td>0.732435</td>\n",
              "      <td>0.879476</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.029122</td>\n",
              "      <td>0.811186</td>\n",
              "      <td>0.866862</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.686801</td>\n",
              "      <td>0.881755</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.017192</td>\n",
              "      <td>0.743223</td>\n",
              "      <td>0.882080</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.014753</td>\n",
              "      <td>0.714514</td>\n",
              "      <td>0.881673</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.013022</td>\n",
              "      <td>0.684037</td>\n",
              "      <td>0.885742</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.011882</td>\n",
              "      <td>0.697414</td>\n",
              "      <td>0.884603</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKixxb5LMqvR"
      },
      "source": [
        "Como podemos ver los resultados son bastante mejores a los obtenidos con anterioridad. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI51AnoYMqvS"
      },
      "source": [
        "### Ejercicio\n",
        "\n",
        "A lo largo de este notebook hemos visto cómo crear 7 modelos que a partir de una secuencia de 3 palabras predicen la siguiente palabra del texto. El ejercicio para esta práctica consite en construir y entrenar esos mismos 7 modelos pero prediciendo una palabra a partir de las tres palabras siguientes que aparecen en la secuencia. Añade a continuación tantas celdas como necesites. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "52ec6745-41d0-4f39-82fc-5c74dd08a058",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVIe2rb6zx_V"
      },
      "source": [
        "L((tokens[i+1:i+4], tokens[i]) for i in range(0,len(tokens)-4,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(['.', 'two', '.'], 'one'),(['three', '.', 'four'], '.'),(['.', 'five', '.'], 'four'),(['six', '.', 'seven'], '.'),(['.', 'eight', '.'], 'seven'),(['nine', '.', 'ten'], '.'),(['.', 'eleven', '.'], 'ten'),(['twelve', '.', 'thirteen'], '.'),(['.', 'fourteen', '.'], 'thirteen'),(['fifteen', '.', 'sixteen'], '.')...]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seqs = L((tensor(nums[i+1:i+4]), nums[i]) for i in range(0,len(nums)-4,3))\n",
        "seqs"
      ],
      "metadata": {
        "id": "z1Cs5QxAZjpM",
        "outputId": "eff7404e-c19c-43e0-9f15-9bb7f7fdf7cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([1, 2, 1]), 0),(tensor([3, 1, 4]), 1),(tensor([1, 5, 1]), 4),(tensor([6, 1, 7]), 1),(tensor([1, 8, 1]), 7),(tensor([ 9,  1, 10]), 1),(tensor([ 1, 11,  1]), 10),(tensor([12,  1, 13]), 1),(tensor([ 1, 14,  1]), 13),(tensor([15,  1, 16]), 1)...]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamaño del batch\n",
        "bs = 64\n",
        "# Partición qu vamos a hacer\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)"
      ],
      "metadata": {
        "id": "2YqKWjHKZ2nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel1(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)"
      ],
      "metadata": {
        "id": "FLGxWoQlZ9ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "id": "0aWE2gGEaTJA",
        "outputId": "4824683d-9758-4f03-b366-2c6a7e98df5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.694356</td>\n",
              "      <td>2.094434</td>\n",
              "      <td>0.467792</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.288059</td>\n",
              "      <td>1.922157</td>\n",
              "      <td>0.481103</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.368533</td>\n",
              "      <td>1.577268</td>\n",
              "      <td>0.496553</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.336855</td>\n",
              "      <td>1.565914</td>\n",
              "      <td>0.496791</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "id": "gk-ycFN2agly",
        "outputId": "47cbd252-2fe8-4402-97e9-7b2774fcf1c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.843124</td>\n",
              "      <td>2.110957</td>\n",
              "      <td>0.431186</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.308514</td>\n",
              "      <td>1.869539</td>\n",
              "      <td>0.473021</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.393011</td>\n",
              "      <td>1.611707</td>\n",
              "      <td>0.486570</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.344017</td>\n",
              "      <td>1.586210</td>\n",
              "      <td>0.492988</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = len(seqs)//bs\n",
        "m,bs,len(seqs)"
      ],
      "metadata": {
        "id": "mEpdNL7lam0A",
        "outputId": "c409ca22-5ee6-45a4-c273-2a6db67bb1e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(328, 64, 21031)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(\n",
        "    group_chunks(seqs[:cut], bs), \n",
        "    group_chunks(seqs[cut:], bs), \n",
        "    bs=bs, drop_last=True, shuffle=False)"
      ],
      "metadata": {
        "id": "q_9Vl8soasfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel3(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "metadata": {
        "id": "jRozsw8Natv9",
        "outputId": "92eea5d4-24bc-479d-96ec-9da6d13c5b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.475952</td>\n",
              "      <td>1.643439</td>\n",
              "      <td>0.554087</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.815944</td>\n",
              "      <td>1.329003</td>\n",
              "      <td>0.684135</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.668486</td>\n",
              "      <td>1.258265</td>\n",
              "      <td>0.665144</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.589775</td>\n",
              "      <td>1.114109</td>\n",
              "      <td>0.712740</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.642669</td>\n",
              "      <td>1.218410</td>\n",
              "      <td>0.684856</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.593083</td>\n",
              "      <td>1.252232</td>\n",
              "      <td>0.662740</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.546609</td>\n",
              "      <td>1.142895</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.486236</td>\n",
              "      <td>1.108077</td>\n",
              "      <td>0.741106</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.458549</td>\n",
              "      <td>1.070816</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.432595</td>\n",
              "      <td>1.095740</td>\n",
              "      <td>0.740625</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls = 16\n",
        "seqs = L((tensor(nums[i:i+ls]), tensor(nums[i+1:i+ls+1]))\n",
        "         for i in range(0,len(nums)-ls-1,ls))\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n",
        "                             group_chunks(seqs[cut:], bs),\n",
        "                             bs=bs, drop_last=True, shuffle=False)"
      ],
      "metadata": {
        "id": "Etb6FnaYbDxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[L(vocab[o] for o in s) for s in seqs[0]]"
      ],
      "metadata": {
        "id": "y5JKNv-_bKch",
        "outputId": "af48d801-920f-4f6c-9536-f7be7f35d3bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n",
              " (#16) ['.','two','.','three','.','four','.','five','.','six'...]]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "id": "WTQHf4T5bNnv",
        "outputId": "bb2b8d34-7ba8-4188-edc4-95d2de313777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.214479</td>\n",
              "      <td>3.006455</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.286663</td>\n",
              "      <td>1.905527</td>\n",
              "      <td>0.438395</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.737020</td>\n",
              "      <td>1.746427</td>\n",
              "      <td>0.464355</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.463982</td>\n",
              "      <td>1.704527</td>\n",
              "      <td>0.529541</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.279438</td>\n",
              "      <td>1.683125</td>\n",
              "      <td>0.533447</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.141250</td>\n",
              "      <td>1.591846</td>\n",
              "      <td>0.541748</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.052245</td>\n",
              "      <td>1.716504</td>\n",
              "      <td>0.528890</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.972835</td>\n",
              "      <td>1.844063</td>\n",
              "      <td>0.512288</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.900994</td>\n",
              "      <td>1.841931</td>\n",
              "      <td>0.513753</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.838867</td>\n",
              "      <td>1.848248</td>\n",
              "      <td>0.533529</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.793362</td>\n",
              "      <td>1.833994</td>\n",
              "      <td>0.551595</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.759822</td>\n",
              "      <td>1.774687</td>\n",
              "      <td>0.556234</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.733702</td>\n",
              "      <td>1.762407</td>\n",
              "      <td>0.569417</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.712209</td>\n",
              "      <td>1.786417</td>\n",
              "      <td>0.565755</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.701205</td>\n",
              "      <td>1.770928</td>\n",
              "      <td>0.568522</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel5(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "id": "oZvFcIPxbSKm",
        "outputId": "196bbd80-9620-49ff-c3cc-f68a62b67c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.090592</td>\n",
              "      <td>2.655104</td>\n",
              "      <td>0.454671</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.161214</td>\n",
              "      <td>1.823684</td>\n",
              "      <td>0.471273</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.700544</td>\n",
              "      <td>1.855709</td>\n",
              "      <td>0.342529</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.472840</td>\n",
              "      <td>1.901712</td>\n",
              "      <td>0.469401</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.303482</td>\n",
              "      <td>2.323605</td>\n",
              "      <td>0.495199</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.167443</td>\n",
              "      <td>2.619432</td>\n",
              "      <td>0.492839</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.055368</td>\n",
              "      <td>2.823949</td>\n",
              "      <td>0.484049</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.959581</td>\n",
              "      <td>2.889572</td>\n",
              "      <td>0.492269</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.873657</td>\n",
              "      <td>2.967640</td>\n",
              "      <td>0.490723</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.802397</td>\n",
              "      <td>3.058379</td>\n",
              "      <td>0.483724</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.745473</td>\n",
              "      <td>3.135635</td>\n",
              "      <td>0.484212</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.703330</td>\n",
              "      <td>3.174062</td>\n",
              "      <td>0.485921</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.672168</td>\n",
              "      <td>3.190799</td>\n",
              "      <td>0.485352</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.653299</td>\n",
              "      <td>3.202880</td>\n",
              "      <td>0.486491</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.643523</td>\n",
              "      <td>3.214074</td>\n",
              "      <td>0.485677</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel6(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 1e-2)"
      ],
      "metadata": {
        "id": "s33hkt8BbWEA",
        "outputId": "798bbaf0-43a5-4bf0-8cbc-26b5db78c0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.019578</td>\n",
              "      <td>2.746136</td>\n",
              "      <td>0.259359</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.231551</td>\n",
              "      <td>2.242202</td>\n",
              "      <td>0.312663</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.628242</td>\n",
              "      <td>2.138380</td>\n",
              "      <td>0.472249</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.321850</td>\n",
              "      <td>1.989188</td>\n",
              "      <td>0.541341</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.077465</td>\n",
              "      <td>2.060928</td>\n",
              "      <td>0.583008</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.787459</td>\n",
              "      <td>1.783174</td>\n",
              "      <td>0.660645</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.525364</td>\n",
              "      <td>1.560822</td>\n",
              "      <td>0.722900</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.355991</td>\n",
              "      <td>1.670435</td>\n",
              "      <td>0.761312</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.229288</td>\n",
              "      <td>1.417489</td>\n",
              "      <td>0.789388</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.142338</td>\n",
              "      <td>1.474035</td>\n",
              "      <td>0.818115</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.090060</td>\n",
              "      <td>1.452279</td>\n",
              "      <td>0.814209</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.057001</td>\n",
              "      <td>1.427104</td>\n",
              "      <td>0.821940</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.039670</td>\n",
              "      <td>1.371069</td>\n",
              "      <td>0.823730</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.031086</td>\n",
              "      <td>1.390543</td>\n",
              "      <td>0.827393</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.027206</td>\n",
              "      <td>1.391285</td>\n",
              "      <td>0.826986</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = TextLearner(dls, LMModel7(len(vocab), 64, 2, 0.4),\n",
        "                    loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
      ],
      "metadata": {
        "id": "6A0GD_uGbavH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ],
      "metadata": {
        "id": "SrpVGNBkbdpG",
        "outputId": "0a938f26-9d20-4804-800b-353f6858a591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.600233</td>\n",
              "      <td>2.159652</td>\n",
              "      <td>0.464762</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.616608</td>\n",
              "      <td>1.251281</td>\n",
              "      <td>0.674642</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.851300</td>\n",
              "      <td>0.802179</td>\n",
              "      <td>0.772624</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.423862</td>\n",
              "      <td>0.560888</td>\n",
              "      <td>0.837484</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.217049</td>\n",
              "      <td>0.503750</td>\n",
              "      <td>0.859049</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.122284</td>\n",
              "      <td>0.506461</td>\n",
              "      <td>0.857422</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.073051</td>\n",
              "      <td>0.441594</td>\n",
              "      <td>0.877604</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.051433</td>\n",
              "      <td>0.378218</td>\n",
              "      <td>0.878988</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.037379</td>\n",
              "      <td>0.355325</td>\n",
              "      <td>0.891113</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.029138</td>\n",
              "      <td>0.370481</td>\n",
              "      <td>0.884603</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.023077</td>\n",
              "      <td>0.356448</td>\n",
              "      <td>0.893799</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.018705</td>\n",
              "      <td>0.284681</td>\n",
              "      <td>0.911621</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.015974</td>\n",
              "      <td>0.328774</td>\n",
              "      <td>0.901611</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.014177</td>\n",
              "      <td>0.287707</td>\n",
              "      <td>0.909261</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.012642</td>\n",
              "      <td>0.290341</td>\n",
              "      <td>0.909098</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GOoxxxcMqvS"
      },
      "source": [
        "Al finalizar recuerda guarda el notebook en tu repositorio de GitHub con la opción *Save in GitHub* del menú *File*."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUOIUhF1zkg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}